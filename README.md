## Usage

For an example of how to use the NN Optimizer package, refer to the `examples/example_usage.py` file. This script demonstrates the process of initializing the MLP model, training it with your data, and making predictions.

## Features

- Activation Functions: Includes ReLU, Sigmoid, Tanh, Softmax, etc.
- Dropout: Provides dropout functionality for neural network regularization.
- Batch Normalization: Helps to speed up training and improve performance.
- Optimizers: Supports various optimization algorithms like SGD, Momentum, NAG, and Adagrad.

## Discussion

Discussion to the NN Optimizer project are welcome. You can contact me by dliu328@wisc.edu
